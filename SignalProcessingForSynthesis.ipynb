{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SignalProcessingForSynthesis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djsabelo/BiosignalsDeepLearningWorkshop/blob/main/SignalProcessingForSynthesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI7mzTAERpq7"
      },
      "source": [
        "# Signal Processing for  Synthesis\n",
        "\n",
        "The application of Deep Learning for biosignals synthesis depends on the quality of signal processing and even on the quality of the raw signal.\n",
        "\n",
        "In this workshop, we will go through the signal processing steps that are usually applied for biosignals synthesis using Python. Here, we will use **numpy** to ease mathematical operations, **matplotlib** to visualize the results of each step, **scipy** for specific processing operations and **os** to search data files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_-lNo7SU3xy"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from scipy.io import loadmat\n",
        "from scipy.signal import decimate"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MiWq2v974vH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9afb8496-517b-4f5a-8ba8-6044af8ec39b"
      },
      "source": [
        "!git clone https://github.com/djsabelo/BiosignalsDeepLearningWorkshop.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'BiosignalsDeepLearningWorkshop' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uagPEw0AU4Gx"
      },
      "source": [
        "## Reading Data\n",
        "\n",
        "The first step for the application of signal processing is to read the files that contain the data. In this case, we will use ECG files from the Fantasia dataset, that were previously downloaded and, so, can be reached using **os**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQNRMGJiUht9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0cf796d-00f1-4f47-e9cc-d7c51b6abdb6"
      },
      "source": [
        "# Find files in folder\n",
        "folder = './BiosignalsDeepLearningWorkshop/data/'\n",
        "files = os.listdir(folder)\n",
        "\n",
        "# Define sampling frequency\n",
        "fs = 250\n",
        "\n",
        "print(files)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['f1o04m.mat', 'f1o03m.mat', 'segments.npy', 'f1o02m.mat', 'f1o01m.mat', 'info', 'f1o05m.mat']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IPMzFo_aMLN"
      },
      "source": [
        "Having the list of files we can now read the data contained in them and store them in a list.\n",
        "\n",
        "However, given that *.mat* files are read as dictionaries, we will simply store the values that correspond to the actual ECG signals. In this case, the key that identifies the signals is *'val'*, thus we index get the values contained in that key.\n",
        "\n",
        "Moreover, each file contains a respiration signal and an ECG signal, but we will keep only the ECG of each file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXvjJJXiaUSq"
      },
      "source": [
        "# Iterate over data files and store the data in a list\n",
        "data = []"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmjeRHYcbDmU"
      },
      "source": [
        "Let's check if the data is in the format we expected. In this case, since the sampling frequency is 250 Hz, we will build a time axis using the function **linspace** from **numpy** Python package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzjHSOpRbXsr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "d2f1077b-3a40-444c-c9da-dd9dddfedf0c"
      },
      "source": [
        "# Get the first signal to plot\n",
        "signal = data[0]\n",
        "\n",
        "# Produce the time axis\n",
        "time = np.arange(0, len(signal)/fs, 1/fs)\n",
        "\n",
        "# Make a figure\n",
        "plt.figure()\n",
        "# Plot the signal in the figure\n",
        "plt.plot(time, signal)\n",
        "# Let's see only part of the signal\n",
        "plt.xlim(500, 508)\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4932cdda88a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the first signal to plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Produce the time axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "altBWvvHgSR2"
      },
      "source": [
        "# Let's see the second signal\n",
        "signal = data[1]\n",
        "time = np.arange(0, len(signal)/fs, 1/fs)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(time, signal)\n",
        "plt.xlim(500, 508)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM9Sdm_kghG6"
      },
      "source": [
        "## Normalise Data\n",
        "\n",
        "The first step of signal processing is to normalise the signals. \n",
        "\n",
        "In this case, we will remove the mean and divide by the maximum of the absolute of the signal so that the resulting values of the signals will be between -0.5 and 0.5.\n",
        "\n",
        "Since we have various signals, we will interate over the list that contains them and will store them in a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yukiQuxqjBrc"
      },
      "source": [
        "# Start the new list\n",
        "normalised_data = []\n",
        "\n",
        "# Iterate over all signals\n",
        "# Remove Mean of signal\n",
        "# Calculate absolute value of signal\n",
        "# Get max value of absolute values of signal\n",
        "# Divide value from the resulte of the remotion of the mean from the signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJwNsbBrk4-0"
      },
      "source": [
        "Let's plot the same portions of the same signals. Note that the values of the y-axis changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUVIi-idk0E7"
      },
      "source": [
        "# Let's see the first normalised signal\n",
        "signal = normalised_data[0]\n",
        "time = np.arange(0, len(signal)/fs, 1/fs)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(time, signal)\n",
        "plt.xlim(500, 508)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfyIXYwclQji"
      },
      "source": [
        "# Let's see the second normalised signal\n",
        "signal = normalised_data[1]\n",
        "time = np.arange(0, len(signal)/fs, 1/fs)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(time, signal)\n",
        "plt.xlim(500, 508)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtJRI8gPleFN"
      },
      "source": [
        "## Subsampling\n",
        "\n",
        "Given that Deep Learning models are \"slow\" during training, due to the number of iterations and complexity of operations that are required, we will subsample our data, which will save us some time when training our model.\n",
        "\n",
        "To do this, we will use _decimate_, which is a function from **scipy** which handles this operation maintaing the integrity of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0T0CoqQpva0"
      },
      "source": [
        "# Build the list to store the subsampled data\n",
        "subsampled_data = []\n",
        "\n",
        "# Iterate over the normalised data and subsample using decimate with factor=5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRw30MdAYf30"
      },
      "source": [
        "Now that we changed the _virtual_ sampling frequency by subsampling the signal, we can define the new value by dividing the original by the factor of subsampling:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diZVkr_hYtq7"
      },
      "source": [
        "fs /= 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHRUcC6Kq7F1"
      },
      "source": [
        "# Let's see the first subsampled signal\n",
        "signal = subsampled_data[0]\n",
        "time = np.arange(0, len(signal)/fs, 1/fs)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(time, signal)\n",
        "plt.xlim(500, 508)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzmV7x6Uq-3c"
      },
      "source": [
        "# Let's see the second subsampled signal\n",
        "signal = subsampled_data[1]\n",
        "time = np.arange(0, len(signal)/fs, 1/fs)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(time, signal)\n",
        "plt.xlim(500, 508)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaBrZt9Qs1Wl"
      },
      "source": [
        "## Denoise Signals\n",
        "\n",
        "An important step in most biosignals processing pipelines is to reduce noise in signals. In this sense, we will implement an average filter, which consists on the substitution of each data point by the mean value of its *n* neighbours.\n",
        "\n",
        "This allows to reduce high frequency noise and to smoothen the signal by choosing a sufficiently large *n*. However, if that value is too large, it will distort the signal and keep only very low frequencies - something we will use to our advantage.\n",
        "\n",
        "However, there is the problem of the extremes, which does not have neighbours in one of their sides (in the beginning there is not previous values and in the end there is no next values). Thus, our first step will be to build a new array that has the length of the signal plus 2 times the number *n* that will serve as the extremes. The new positions will be filled mirroring of the signal relative to the extremes.\n",
        "\n",
        "We will use the previously defined signal and *n*=3 for the development."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm2qqbVIzXj1"
      },
      "source": [
        "# Define n\n",
        "n = 3\n",
        "\n",
        "# Make an array containing only zeros and with length = length_of_signal + 2*n\n",
        "extremes_zeros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juKIT3cD8lvU"
      },
      "source": [
        "To make this new array, we will iterate over the subsampled signal and fill the new array according to our description. Thus, the first value of the new array will correspond to the *n*-th value of the subsampled array, the second value will correspond to the *n-1*-th value and so on. When we reach the end of the signal, once we want to mirror the extremes, we fill the next position with the previous value and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbAx-bSD9IHc"
      },
      "source": [
        "# Iterate over the one signal and fill the \"extreme_zeros\" array appropriately:\n",
        "  # Mirror the start of the signal\n",
        "  # Mirror the end of the signal\n",
        "  # Fill the remaining with the signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAKb4YAZ9XY-"
      },
      "source": [
        "To show the resulting array, we will plot it and show also the subsampled array you previously saw."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M7uN-GR9k7V"
      },
      "source": [
        "# Let's see the auxiliary signal\n",
        "mirror_time = np.arange(0, len(extremes_zeros)/fs, 1/fs)\n",
        "\n",
        "# These prints should be \"True\"\n",
        "print(all(extremes_zeros[n:-n] == signal))\n",
        "print(all(extremes_zeros[:n+1] == signal[:n+1][::-1]))\n",
        "print(all(extremes_zeros[-n-1:] == signal[-n-1:][::-1]))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(mirror_time, extremes_zeros)\n",
        "plt.plot(time + n/fs, signal)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0fjw6MpA7SE"
      },
      "source": [
        "Now that we have our auxiliary array with all the values we need, let's build the new array and fill each position with the mean value of its *n* neighbours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4e_P0XgA6Yl"
      },
      "source": [
        "# Build the array\n",
        "smoothen_signal = np.zeros(len(signal))\n",
        "\n",
        "# Fill the array with the appropriate values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgC-w4H4B_CW"
      },
      "source": [
        "Let's check the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY1U6mBjB-Qh"
      },
      "source": [
        "# Let's see the smoothened signal\n",
        "print(smoothen_signal)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(time, smoothen_signal)\n",
        "plt.xlim(500, 508)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkT-TM4iC4a3"
      },
      "source": [
        "To facilitate our job later on, we will save this part of the code in a reusable function that can be run whenever we want. As arguments, we will have the signal and the value *n* and the function will return the smoothened signal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRh5b9GNDHeY"
      },
      "source": [
        "def smooth(signal, n):\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax2P-thbDh3O"
      },
      "source": [
        "We can now iterate over the subsampled signals, apply this function and save the resulting smoothened signals in a new list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs2qxpY3Dqd9"
      },
      "source": [
        "# Build the list where we will save the smoothened signals to\n",
        "smoothened_data = []\n",
        "\n",
        "# Iterate over the subsampled data, smoothen the signals and stored them in smoothened_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQICtgNoEO9g"
      },
      "source": [
        "## Remove Baseline Wander\n",
        "\n",
        "The previous step allowed us to remove high-frequency noise from the signal, however, we still need to take care of the low-frequency noise that appears as baseline wander. This kind of noise can be originated by the respiration process which changes the distance between the ECG electrodes when the chest is expanding and contracting.\n",
        "\n",
        "To reduce this kind of noise we can resource to the smooth function that we previously defined. Namely, if we define a sufficiently large *n* we will keep only the low-frequency components of the signal, which is what we want to remove. Thus, we simply need to subtracte this result from our signal.\n",
        "\n",
        "Let's see how to do just this.\n",
        "\n",
        "The first step will be to apply the smoothing function with *n*=40 (a large number) to the previously defined signal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2dy3nYYEOX6"
      },
      "source": [
        "signal = smoothened_signal\n",
        "\n",
        "# Calculate the baseline wander using n=40 and the smooth function we defined\n",
        "baseline_wander"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrTRGf3zFV2O"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(signal)\n",
        "plt.plot(baseline_wander)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2WGyTPzcRq6"
      },
      "source": [
        "The next step consists on subtracting this low-frequency signal from the original signal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuvGq378Fj2Y"
      },
      "source": [
        "# Subtract the baseline_wander signal from the signal\n",
        "filtered_signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FugpNnvFo7x"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(signal)\n",
        "plt.plot(filtered_signal)\n",
        "plt.plot(baseline_wander)\n",
        "plt.xlim(75000, 75908)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1coEoQP2GuNg"
      },
      "source": [
        "So, we can apply this to all our signals and save them in a new list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq5I-9D6Gza9"
      },
      "source": [
        "# Build the list where we will save the denoised signals to\n",
        "denoised_data = []\n",
        "\n",
        "# Iterate over the smoothened signals, remove baseline wander and store them in denoised_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmNedoG1faYc"
      },
      "source": [
        "## Remove minimum\n",
        "\n",
        "The next step is to subtract the minimum value from the signal so that the values are in interval [0, 1], which will be useful for the Deep Learning algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4ydNcFpf07N"
      },
      "source": [
        "signal = denoised_signal\n",
        "\n",
        "# Subtract the minimum value of the signal\n",
        "interval_signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSBmXe0Df8zb"
      },
      "source": [
        "Let's plot both signals to see the difference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2-evrMrgBMb"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(signal)\n",
        "plt.plot(interval_signal)\n",
        "plt.xlim(75000, 75908)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnCzwZwWgQ9Y"
      },
      "source": [
        "Now we will apply the same processing step to all denoised signals and store them in a list for later utilization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo20M0bJgbA0"
      },
      "source": [
        "# Build the list where we will save the new signals to\n",
        "interval_data = []\n",
        "\n",
        "# Iterate over the filtered signals, apply the same processing and store the results in interval_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xWA_QXegvEb"
      },
      "source": [
        "## Quantization\n",
        "\n",
        "Quantization is an essential step in Deep Learning applications and consists on reducing the dimensionality of our dataset by defining a given range of possible values that the signal can have.\n",
        "\n",
        "Thus, if we define that the number of possible values is *d*, then we divide the range of values that the signal currently has (between 0 and 1 in our case) by *d* and then, we map each current value to the corresponding new value. \n",
        "\n",
        "Let's use the last defined *signal* variable and *d*=1000 to visualise what we mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbKHPeVZifik"
      },
      "source": [
        "d = 1000\n",
        "signal = interval_signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W__LyBe4kw7U"
      },
      "source": [
        "Since the lowest possible value is 0 and the highest possible value is **d** times max(signal), we will first multiply **d** by our signal in order to convert it to the new scale. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GODFxowWij9G"
      },
      "source": [
        "# Scale the signal\n",
        "scaled_signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMS62_hhlHNW"
      },
      "source": [
        "Then, we need to round each resulting value to the closest integer and cast it to **int**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R6m624Mlkit"
      },
      "source": [
        "# Round to integers\n",
        "rounded_signal\n",
        "\n",
        "# Cast them to int\n",
        "quantised_signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgZdGvfemLZF"
      },
      "source": [
        "The result depends on the number *d* we choose. For example, for *d*=1000, we will have:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeQ-OAoEmFMV"
      },
      "source": [
        "plt.plot(quantised_signal);\n",
        "plt.xlim(75400, 75908)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNfhNAkjo9D9"
      },
      "source": [
        "Let's try the same procedure with a much smaller *d* to see the differences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTAzNkLmpDI1"
      },
      "source": [
        "d = 50\n",
        "# Copy the code above here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dfLCiNoo1N_"
      },
      "source": [
        "plt.plot(quantised_signal);\n",
        "plt.xlim(75400, 75908)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ8BQqJlpMl3"
      },
      "source": [
        "So, we are reducing the dimensionality of the data and the signal becomes more \"squared\". This will allow our Deep Learning model to learn the values much easier as there are fewer values to pick from.\n",
        "\n",
        "However, to keep the shape of the signal, we will use *d* = 1000 and apply this processing step to all our signals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjqpJgpvpMJE"
      },
      "source": [
        "d = 1000\n",
        "\n",
        "# Build the list where we will save the new signals to\n",
        "quantised_data = []\n",
        "\n",
        "# Iterate over the interval data, quantise each signal and store them"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RFsWdLPqJb3"
      },
      "source": [
        "## Segmentation\n",
        "\n",
        "The last processing step will be the segmentation of our signal. In this case, since our problem is to synthesise signals, we need to use a sliding window segmentation procedure with overlap. Each segment must have at least 2 heartbeats and the size of each segment must have a number 2<sup>n</sup>+1 of data points. Moreover, we will use overlap to increase the size of our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G-MlKiqu-fR"
      },
      "source": [
        "signal = quantised_signal\n",
        "size_of_segment = 257 # 2^8 + 1\n",
        "step = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2apGUw9pvymG"
      },
      "source": [
        "# List where we will store the segments of the signal\n",
        "segments = []\n",
        "\n",
        "# Iterate over the signal with a step size corresponding to the overlap\n",
        "  # Save each segment in segments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rmVBfXRwqIt"
      },
      "source": [
        "Let's see some segments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jsm7Gctwt52"
      },
      "source": [
        "for segment in segments[:10]:\n",
        "  plt.figure()\n",
        "  plt.plot(segment)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "celssjHBx7z1"
      },
      "source": [
        "Finally, our task is to do the same for all signals. Once again, we will build a function that can be invoked whenever we want to improce code readibility. This function will have the signal, the size of segments and the step as arguments and will return the list of segments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu6ltvU5x27x"
      },
      "source": [
        "def segmentation(signal, size_of_segment, step):\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4_l5RMFye5P"
      },
      "source": [
        "Now we can use this function and apply it to all of our signals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0EqlIEGyj5V"
      },
      "source": [
        "d = 1000\n",
        "\n",
        "# Build the list where we will save the new signals to\n",
        "segmented_data = []\n",
        "\n",
        "# Iterate over the quantised data, segment the signals and save them in segmented_data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}